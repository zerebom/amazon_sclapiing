{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DBからtextデータのみをとってきて特定のLenになるまで結合する。  \n",
    "まだ２０００字でしかやっていない。そしてそれを新しいDBに入れている。  \n",
    "その後MeCabを使って、形態素解析し、縦（語彙）×横（レビュー番号）のcsvを作成、保存している。  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys;sys.path.append('./src')\n",
    "import sqlite3\n",
    "import re\n",
    "from DB import *\n",
    "from NLP import *\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import numpy as np\n",
    "import re \n",
    "from collections import Counter\n",
    "import urllib.request as urllib\n",
    "from bs4 import BeautifulSoup\n",
    "import sqlite3\n",
    "import time\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from contextlib import closing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_txt2(text_data):\n",
    "    # text_data=re.sub('\\（.+\\）','',text_data)\n",
    "#     text_data=re.sub('.+　','',text_data)\n",
    "    text_data=re.sub('\\n','',text_data)\n",
    "    text_data=re.sub('\\\\u3000','',text_data)\n",
    "    text_data=text_data.split('。')\n",
    "    return(text_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_category_db='../data/database/1112_low_prodcuts_text_category.db'\n",
    "high_category_db='../data/database/1112_high_prodcuts_text_category.db'\n",
    "Hconn2,Hc2=get_db_conn(high_category_db)\n",
    "Lconn2,Lc2=get_db_conn(low_category_db)\n",
    "\n",
    "\n",
    "high_text_db='../data/database/1120_high_ML_text.db'\n",
    "Hconn3,Hc3=get_db_conn(high_text_db)\n",
    "low_text_db='../data/database/1120_low_ML_text.db'\n",
    "Lconn3,Lc3=get_db_conn(low_text_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #最初にDBを作るセルなので今はもういらない\n",
    "# Hc2.execute('''select distinct id,username,text_len,pd_text from product_text where text_len!='no_datas' ''')\n",
    "# Hc3.execute('''create table ML_text(id integer primary key,text_len,pd_text)''')\n",
    "\n",
    "# i=0\n",
    "# j=0\n",
    "# datas=[]\n",
    "# sum_len=0\n",
    "# sum_text=''\n",
    "# for row in Hc2:\n",
    "#     i+=1\n",
    "#     print(i,end=' ')\n",
    "#     len_=row[2]\n",
    "#     pd_text=row[3]\n",
    "#     sum_len+=int(len_)\n",
    "#     sum_text+=pd_text\n",
    "#     if sum_len>=2000:\n",
    "#         j+=1\n",
    "#         print(f'j={j},i={i}')\n",
    "#         print(sum_len)\n",
    "#         datas.append((sum_len,sum_text))\n",
    "#         sum_len=0\n",
    "#         sum_text=''\n",
    "# print(len(datas))\n",
    "\n",
    "# insert_sql = 'insert into ML_text (text_len,pd_text) values (?,?)'\n",
    "# Hc3.executemany(insert_sql, datas)\n",
    "# Hconn3.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Lc3.execute('''create table ML_text(id integer primary key,text_len,pd_text)''')\n",
    "# Lc2.execute('''select distinct id,username,text_len,pd_text from product_text where text_len!='no_datas' ''')\n",
    "# i=0\n",
    "# j=0\n",
    "# datas=[]\n",
    "# sum_len=0\n",
    "# sum_text=''\n",
    "# for row in Lc2:\n",
    "#     i+=1\n",
    "#     print(i,end=' ')\n",
    "#     len_=row[2]\n",
    "#     pd_text=row[3]\n",
    "#     sum_len+=int(len_)\n",
    "#     sum_text+=pd_text\n",
    "#     if sum_len>=2000:\n",
    "#         j+=1\n",
    "#         print(f'j={j},i={i}')\n",
    "# #         print(sum_len)\n",
    "#         datas.append((sum_len,sum_text))\n",
    "#         sum_len=0\n",
    "#         sum_text=''\n",
    "# print(len(datas))\n",
    "\n",
    "# insert_sql = 'insert into ML_text (text_len,pd_text) values (?,?)'\n",
    "# Lc3.executemany(insert_sql, datas)\n",
    "# Lconn3.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lc3.execute('''select distinct text_len,pd_text from ML_text  ''')\n",
    "ldf=pd.DataFrame()\n",
    "i=0\n",
    "for row in Lc3:\n",
    "    a=clean_txt(str(row[1]))\n",
    "    a=count_matubi(a,3)\n",
    "    ldf=count_to_pd(ldf,i,a)\n",
    "    i+=1\n",
    "    print(i,end='')\n",
    "ldf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldf['sum']=ldf.sum(axis=1)\n",
    "ldf.sort_values(by='sum',ascending=False)\n",
    "ldf.to_csv('./1121low.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goi_df=pd.read_csv('../data/goi/goi.csv',encoding='shift-jis')\n",
    "goiword=list(goi_df['標準的な表記'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lc3.execute('''select distinct text_len,pd_text from ML_text  ''')\n",
    "ldf_mor=pd.DataFrame()\n",
    "i=0\n",
    "for row in Lc3:\n",
    "    a=clean_txt2(str(row[1]))\n",
    "    a=count_morphemes(a,goiword,goihyo_flg=False)\n",
    "    try:\n",
    "        ldf_mor=count_to_pd(ldf_mor,i,a)\n",
    "    except:\n",
    "        continue\n",
    "    i+=1\n",
    "    print(i,end=',')\n",
    "ldf_mor.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ldf_mor.head(30)\n",
    "ldf_mor['sum']=ldf_mor.sum(axis=1)\n",
    "ldf_mor.sort_values(by='sum',ascending=False,inplace=True)\n",
    "ldf_mor.to_csv('./1121low_mor.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Hc3.execute('''select distinct text_len,pd_text from ML_text  ''')\n",
    "hdf_mor=pd.DataFrame()\n",
    "i=0\n",
    "for row in Hc3:\n",
    "    a=clean_txt2(str(row[1]))\n",
    "    a=count_morphemes(a,goiword,goihyo_flg=False)\n",
    "    try:\n",
    "        hdf_mor=count_to_pd(hdf_mor,i,a)\n",
    "    except:\n",
    "        continue\n",
    "    i+=1\n",
    "    print(i,end=',')\n",
    "hdf_mor.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf_mor['sum']=hdf_mor.sum(axis=1)\n",
    "hdf_mor.sort_values(by='sum',ascending=False,inplace=True)\n",
    "hdf_mor.to_csv('./1121high_mor.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=5\n",
    "if a==4 or not a==5:\n",
    "    print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
